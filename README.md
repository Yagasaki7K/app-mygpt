<p align="center">
  <img
    src="https://github.com/user-attachments/assets/3c03aa7e-9d14-4c92-84f1-a887ca66f7af"
    alt="image"
    width="1899"
    height="926"
  />
</p>

# MyGPT (secure local multi-LLM)

MyGPT is a local interface to chat with multiple large language models (LLMs) in one place, keeping your keys and history under your control. It works with any provider compatible with the OpenAI-style API (`chat/completions`) and lets you switch models quickly without exposing tokens in the front-end.

## Key benefits

- **Centralizes multiple LLMs in one dashboard**: switch between Gemini, OpenAI, Claude, Copilot (or any compatible provider) without leaving the app.
- **Local and secure execution**: the back end runs locally and makes requests directly to providers; tokens stay on the server and/or in your `.env`.
- **Local history**: your conversations are stored locally and can be exported/imported as JSON.
- **Fast, lightweight interface**: UI built with React + Vite with a focus on usability.

## How it works (overview)

1. **Front-end** (React/Vite) renders the chat UI and model selector.
2. **Local back-end** (Elysia/Node) receives messages, resolves tokens from `.env`, and forwards them to the provider.
3. **Local persistence**: history and providers are stored in `history.json` and `providers.json`.

## Requirements

- Node.js 18+ (recommended)
- npm (or another package manager, but the commands below use npm)

## Token configuration (required for use)

1. **Create the `.env` file** from the example:

   ```bash
   cp .env.example .env
   ```

2. **Fill in your keys** in `.env`:

   ```env
   GEMINI_TOKEN=...
   OPENAI_TOKEN=...
   CLAUDE_TOKEN=...
   COPILOT_TOKEN=...
   TOKEN=... # optional generic token used by providers
   ```

> âš ï¸ `.env` is never committed. It is ignored by `.gitignore`.

## Provider setup

Providers are configured in `providers.json`. Each entry requires:

- `model`: model name to send in the payload
- `url`: OpenAI-compatible endpoint
- `token`: literal token **or** an environment variable reference like `${GEMINI_TOKEN}`

Example:

```json
[
  {
    "model": "gemini-1.5-pro",
    "url": "https://generativelanguage.googleapis.com/v1beta/openai/chat/completions",
    "token": "${GEMINI_TOKEN}"
  }
]
```

You can also reference environment variables in the URL or token using:

- `${TOKEN}`
- `env:TOKEN`
- `process.env.TOKEN`

> ğŸ” **Best practices**: always use `${VARIABLE_NAME}` (or `process.env.VARIABLE_NAME`) in `providers.json` to keep tokens out of the repo.

## Running locally

1. Install dependencies:

   ```bash
   npm install
   ```

2. Start the development environment:

   ```bash
   npm run dev
   ```

This starts:

- **Local API** at `http://localhost:5174`
- **Front-end** at `http://localhost:5173`

## Basic usage

1. Open the application in your browser.
2. Select a provider/model at the top.
3. Send messages normally.
4. Export/import history when needed.

## Security

- Tokens stay on the server and/or `.env`.
- The front-end never receives your tokens.
- History stays on your machine (local file).

## Project structure

```
.
â”œâ”€â”€ server.js         # Local API that talks to providers
â”œâ”€â”€ providers.json    # Provider list (with tokens/variables)
â”œâ”€â”€ history.json      # Locally persisted history
â”œâ”€â”€ src/              # React front-end
â””â”€â”€ .env.example      # Environment variable example
```

## Tips

- To add new providers, add more objects to `providers.json`.
- To rotate tokens, edit only `.env`.
- You can also add providers via the UI ("Add provider" button).

## License

Free to use for personal and internal purposes.

---

# MyGPT (multi-LLM local seguro)

O MyGPT Ã© uma interface local para conversar com mÃºltiplos modelos de linguagem (LLMs) em um Ãºnico lugar, mantendo suas chaves e histÃ³rico sob seu controle. Ele funciona com qualquer provedor compatÃ­vel com a API estilo OpenAI (endpoint de `chat/completions`) e permite alternar modelos rapidamente sem expor tokens no front-end.

## Principais benefÃ­cios

- **Centraliza LLMs em um Ãºnico painel**: alterne entre Gemini, OpenAI, Claude, Copilot (ou outros compatÃ­veis) sem sair da aplicaÃ§Ã£o.
- **ExecuÃ§Ã£o local e segura**: o back-end roda localmente e faz as requisiÃ§Ãµes diretamente aos provedores; tokens ficam no servidor e/ou no seu `.env`.
- **HistÃ³rico local**: suas conversas sÃ£o persistidas localmente e podem ser exportadas/importadas via JSON.
- **Interface rÃ¡pida e leve**: UI feita em React + Vite com foco em usabilidade.

## Como funciona (visÃ£o geral)

1. **Front-end** (React/Vite) exibe a interface de chat e o seletor de modelos.
2. **Back-end local** (Elysia/Node) recebe as mensagens, resolve os tokens do `.env` e encaminha para o provedor.
3. **PersistÃªncia local**: o histÃ³rico e a lista de provedores ficam em `history.json` e `providers.json`.

## Requisitos

- Node.js 18+ (recomendado)
- npm (ou outro gerenciador, mas os comandos abaixo usam npm)

## ConfiguraÃ§Ã£o de tokens (obrigatÃ³rio para uso)

1. **Crie o arquivo `.env`** a partir do exemplo:

   ```bash
   cp .env.example .env
   ```

2. **Preencha suas chaves** no `.env`:

   ```env
   GEMINI_TOKEN=...
   OPENAI_TOKEN=...
   CLAUDE_TOKEN=...
   COPILOT_TOKEN=...
   TOKEN=... # token genÃ©rico opcional usado pelos provedores
   ```

> âš ï¸ O `.env` nunca Ã© commitado. Ele fica ignorado no `.gitignore`.

## Cadastro de provedores

Os provedores sÃ£o configurados no arquivo `providers.json`. Cada entrada exige:

- `model`: nome do modelo a ser enviado no payload
- `url`: endpoint compatÃ­vel com OpenAI
- `token`: token literal **ou** referÃªncia a variÃ¡vel de ambiente, como `${GEMINI_TOKEN}`

Exemplo:

```json
[
  {
    "model": "gemini-1.5-pro",
    "url": "https://generativelanguage.googleapis.com/v1beta/openai/chat/completions",
    "token": "${GEMINI_TOKEN}"
  }
]
```

VocÃª tambÃ©m pode referenciar variÃ¡veis de ambiente na URL ou no token usando:

- `${TOKEN}`
- `env:TOKEN`
- `process.env.TOKEN`

> ğŸ” **Boas prÃ¡ticas**: use sempre `${NOME_DA_VARIAVEL}` (ou `process.env.NOME_DA_VARIAVEL`) no `providers.json` para manter seus tokens fora do repo.

## Executando localmente

1. Instale dependÃªncias:

   ```bash
   npm install
   ```

2. Rode o ambiente de desenvolvimento:

   ```bash
   npm run dev
   ```

Isso inicia:

- **API local** em `http://localhost:5174`
- **Front-end** em `http://localhost:5173`

## Uso bÃ¡sico

1. Abra a aplicaÃ§Ã£o no navegador.
2. Selecione um provedor/modelo no topo.
3. Envie mensagens normalmente.
4. Exporte/importa histÃ³rico quando necessÃ¡rio.

## SeguranÃ§a

- Tokens ficam no servidor e/ou `.env`.
- O front-end nunca recebe seus tokens.
- O histÃ³rico permanece no seu computador (arquivo local).

## Estrutura do projeto

```
.
â”œâ”€â”€ server.js         # API local que conversa com os provedores
â”œâ”€â”€ providers.json    # Lista de provedores (com tokens/variÃ¡veis)
â”œâ”€â”€ history.json      # HistÃ³rico persistido localmente
â”œâ”€â”€ src/              # Front-end React
â””â”€â”€ .env.example      # Exemplo de variÃ¡veis de ambiente
```

## Dicas

- Para adicionar novos provedores, basta inserir mais objetos no `providers.json`.
- Para trocar tokens, edite apenas o `.env`.
- Se preferir, vocÃª pode cadastrar provedores pela UI (botÃ£o â€œAdicionar provedorâ€).

## LicenÃ§a

Uso livre para fins pessoais e internos.
