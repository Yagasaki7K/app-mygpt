# MyGPT (multi-LLM local seguro)

O MyGPT Ã© uma interface local para conversar com mÃºltiplos modelos de linguagem (LLMs) em um Ãºnico lugar, mantendo suas chaves e histÃ³rico sob seu controle. Ele funciona com qualquer provedor compatÃ­vel com a API estilo OpenAI (endpoint de `chat/completions`) e permite alternar modelos rapidamente sem expor tokens no front-end.

## Principais benefÃ­cios

- **Centraliza LLMs em um Ãºnico painel**: alterne entre Gemini, OpenAI, Claude, Copilot (ou outros compatÃ­veis) sem sair da aplicaÃ§Ã£o.
- **ExecuÃ§Ã£o local e segura**: o back-end roda localmente e faz as requisiÃ§Ãµes diretamente aos provedores; tokens ficam no servidor e/ou no seu `.env`.
- **HistÃ³rico local**: suas conversas sÃ£o persistidas localmente e podem ser exportadas/importadas via JSON.
- **Interface rÃ¡pida e leve**: UI feita em React + Vite com foco em usabilidade.

## Como funciona (visÃ£o geral)

1. **Front-end** (React/Vite) exibe a interface de chat e o seletor de modelos.
2. **Back-end local** (Elysia/Node) recebe as mensagens, resolve os tokens do `.env` e encaminha para o provedor.
3. **PersistÃªncia local**: o histÃ³rico e a lista de provedores ficam em `history.json` e `providers.json`.

## Requisitos

- Node.js 18+ (recomendado)
- npm (ou outro gerenciador, mas os comandos abaixo usam npm)

## ConfiguraÃ§Ã£o de tokens (obrigatÃ³rio para uso)

1. **Crie o arquivo `.env`** a partir do exemplo:

   ```bash
   cp .env.example .env
   ```

2. **Preencha suas chaves** no `.env`:

   ```env
   GEMINI_TOKEN=...
   OPENAI_TOKEN=...
   CLAUDE_TOKEN=...
   COPILOT_TOKEN=...
   ```

> âš ï¸ O `.env` nunca Ã© commitado. Ele fica ignorado no `.gitignore`.

## Cadastro de provedores

Os provedores sÃ£o configurados no arquivo `providers.json`. Cada entrada exige:

- `model`: nome do modelo a ser enviado no payload
- `url`: endpoint compatÃ­vel com OpenAI
- `token`: token literal **ou** referÃªncia a variÃ¡vel de ambiente, como `${GEMINI_TOKEN}`

Exemplo:

```json
[
  {
    "model": "gemini-1.5-pro",
    "url": "https://generativelanguage.googleapis.com/v1beta/openai/chat/completions",
    "token": "${GEMINI_TOKEN}"
  }
]
```

> ğŸ” **Boas prÃ¡ticas**: use sempre `${NOME_DA_VARIAVEL}` no `providers.json` para manter seus tokens fora do repo.

## Executando localmente

1. Instale dependÃªncias:

   ```bash
   npm install
   ```

2. Rode o ambiente de desenvolvimento:

   ```bash
   npm run dev
   ```

Isso inicia:

- **API local** em `http://localhost:5174`
- **Front-end** em `http://localhost:5173`

## Uso bÃ¡sico

1. Abra a aplicaÃ§Ã£o no navegador.
2. Selecione um provedor/modelo no topo.
3. Envie mensagens normalmente.
4. Exporte/importa histÃ³rico quando necessÃ¡rio.

## SeguranÃ§a

- Tokens ficam no servidor e/ou `.env`.
- O front-end nunca recebe seus tokens.
- O histÃ³rico permanece no seu computador (arquivo local).

## Estrutura do projeto

```
.
â”œâ”€â”€ server.js         # API local que conversa com os provedores
â”œâ”€â”€ providers.json    # Lista de provedores (com tokens/variÃ¡veis)
â”œâ”€â”€ history.json      # HistÃ³rico persistido localmente
â”œâ”€â”€ src/              # Front-end React
â””â”€â”€ .env.example      # Exemplo de variÃ¡veis de ambiente
```

## Dicas

- Para adicionar novos provedores, basta inserir mais objetos no `providers.json`.
- Para trocar tokens, edite apenas o `.env`.
- Se preferir, vocÃª pode cadastrar provedores pela UI (botÃ£o â€œAdicionar provedorâ€).

## LicenÃ§a

Uso livre para fins pessoais e internos.
